
# Generative Adversarial Network (GAN) for Image Synthesis

This Jupyter notebook demonstrates training a **Generative Adversarial Network (GAN)** on the **MNIST** dataset using **TensorFlow / Keras**. It includes data preparation, generator and discriminator definitions, the adversarial training loop, and visualization of generated samples.

> Project file: `Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ_GAN,_Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ_Ğ¾Ğ±Ñ€Ğ°Ğ·Ñ†Ğ¾Ğ²_Ğ¾Ğ´ĞµĞ¶Ğ´Ñ‹.ipynb`

## ğŸ§° Tech stack
- `tensorflow`, `tensorflow.keras`
- `tensorflow_datasets` (MNIST loading)
- `numpy`
- `matplotlib`

## ğŸ“¦ Data
- Dataset: **MNIST** (loaded via `tensorflow_datasets`).
- Preprocessing: normalization of images to `[-1, 1]` to stabilize GAN training.

## ğŸ—ï¸ Architecture
- **Generator**: Keras (Sequential) network with transposed convolutions / dense layers that maps a latent vector to an image.
- **Discriminator**: convolutional / dense network that classifies images as real or fake.
- **Optimizers & losses**: standard GAN training setup implemented with Keras.

## ğŸš€ Experiment flow
1. Load and prepare MNIST (`tensorflow_datasets`).
2. Define generator and discriminator (Keras).
3. Train the GAN adversarially (training loop).
4. Visualize training progress and generated samples.

## ğŸ“Š Outputs
- Saved/plotted generated images produced during training.
- Visual inspection of sample quality and training dynamics via plots.

## ğŸ“„ Contents
- Notebook: `Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ_GAN,_Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ_Ğ¾Ğ±Ñ€Ğ°Ğ·Ñ†Ğ¾Ğ²_Ğ¾Ğ´ĞµĞ¶Ğ´Ñ‹.ipynb` â€” includes data prep, model definitions, and the training loop.


